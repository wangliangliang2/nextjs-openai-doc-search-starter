### **基本选项**


  * 新建或已有的Pipeline名称(`pandora_workflow_name`)：必填，七牛大数据平台Pipeline名称，如果不存在会新建，如果存在会使用已有的。
  
  * 新建或已有的实时仓库名称(`pandora_repo_name`): 必填，智能日志管理平台的实时仓库名称，如果不存在会新建，如果存在会使用已有的。
  
  * 自动创建并导出到日志管理查询仓库(`pandora_enable_logdb`): 默认为开启，该字段表示用户启动 `自动创建实时仓库并更新` 状态下直接将数据导出到 智能日志仓库。所以该项生效的前提是 `自动创建实时仓库并更新`是开启的。该配置会自动创建日志查询的仓库，同时在 `自动创建实时仓库并更新` 字段增加的情况下更新日志检索服务的仓库，更新导出。 注意，**自动创建的日志查询仓库，数据默认保存 `30` 天，如需长时间保存，请到七牛官方日志检索服务页面修改数据仓库的数据保存时间；对于已经存在的实时仓库，并且已经创建过同名导出，自动创建导出将不生效；自动创建导出的仓库名称需要统一为小写，查询仓库命名的仓库名称不支持大写**。
  
  * 自动导出到七牛云存储(`pandora_enable_kodo`): 默认不启用，该字段表示是否在用户启动 `自动创建实时仓库并更新` 状态下直接将数据导出到七牛云存储。所以该项生效的前提是 `自动创建实时仓库并更新`是开启的。注意：**该配置不会自动创建云存储的桶(bucket)，使用该功能注意提前创建桶(bucket)，同时在 `自动创建实时仓库并更新`状态下，字段增加的情况也会自动更新导出。 注意，v0.2.0版本默认自动导出到云存储的数据默认保存 30 天，如需长时间保存，请到 大数据平台(Pipeline) 页面修改导出的数据保存时间， v0.2.0以后的版本默认为永久保存，如需修改，也请到大数据平台(Pipeline) 页面修改导出的数据保存时间**。
  

### **高级选项**

  * 自动创建实时仓库并更新(`pandora_schema_free`): 默认开启，该字段表示在用户数据中出现新字段时就更新实时仓库，添加字段，如果实时仓库不存在，则自动创建仓库。启用该功能最大的好处是，免除了数据字段更新导致仓库数据字段少收集或无法收集的困扰，使得用户可以从`字段及类型`配置中解放出来，无需在意解析到的字段名称。特别适合 logkit-pro 的入门用户，一开始可以使用 `自动创建实时仓库并更新(pandora_schema_free)` 功能，快速将数据发送到实时仓库。注意，目前自动推导支持所有实时仓库的数据类型，但是仅符合 `RFC3339` 格式的 `string` 会推导成 `date` 类型，其他都是按照数据的原始类型推导。具体的字段类型可以在 [Pipeline 数据源](/insight/manual/4689/the-data-source)查看。
  
  * 以 DSL 语法自动创建实时仓库(`pandora_auto_create`): 该字段默认为空，不自动创建。使用该功能的场景一是为没有开启`自动创建实时仓库并更新(pandora_schema_free)`的用户，希望提前创建好实时仓库。填写该字段后，会自动创建实时仓库；二是某些字段自动推导的可能不准确，希望提前指定字段类型。若实时仓库已存在，则在已存在的实时仓库上添加字段。 仓库的 `DSL` 创建规则为 `<字段名称> <类型>`,字段名称和类型用`空格符( )`隔开，不同字段用`逗号(,)`隔开。如果开启了 `自动创建实时仓库并更新(pandora_schema_free)` 这里只要声明部分想要指定的字段和类型即可，无需写完整。
    * `date` 类型：`date`,`DATE`,`d`,`D`
    * `long` 类型：`long`,`LONG`,`l`,`L`
    * `float` 类型: `float`,`FLOAT`,`F`,`f`
    * `string` 类型: `string`,`STRING`,`S`,`s`
    * `bool` 类型: `bool`,`BOOL`,`B`,`b`,`boolean`
    * `array` 类型: `array`,`ARRAY`,`A`,`a`;括号中跟具体`array`元素的类型，如`a(l)`，表示`array`里面都是`long`。同时，也可以省略小括号前的`array`字符，直接写`(l)`，表示 `array`类型，里面的元素是`long`
    * `map` 类型: `map`,`MAP`,`M`,`m`;使用花括号表示描述`map`里面的元素名称和类型，如`map{a l,b map{c b,x s}}`, 表示map结构体里包含`a`字段，类型是`long`，`b`字段又是一个map，里面包含`c`字段，类型是`bool`，还包含`x`字段，类型是`string`。同时，也可以省略花括号前面的`map`字符，直接写`{s l}`,表示map类型，里面的元素`s`为`long`类型。

  * 实时仓库数据传输域名(`pandora_host`): 必填，服务地址，默认为 `https://nb-pipeline.qiniuapi.com`。

  * 指定日志搜索仓库名称(`pandora_logdb_name`): 默认与实时仓库名称相同，可指定 `自动创建并导出到日志管理查询仓库(pandora_enable_logdb)` 功能创建的日志搜索仓库名称。

  * 日志搜索域名(`pandora_logdb_host`): 默认为 `https://nb-insight.qiniuapi.com`，创建日志搜索仓库的服务地址。

  * 指定字段分词方式(`pandora_logdb_analyzer`): 默认情况下，logkit创建的日志搜索仓库分词方式为全文索引，索引字段采用不分词的策略。 当默认的情况不符合需求时，可以通过该字段指定分词方式。指定字段的分词方式由字段名称和分词方式名称通过空格拼接，逗号分隔多个，如 "f1 keyword, f2 full_text, f3.f4 standard", 表示 f1 字段指定分词方式为keyword， f2 字段指定分词方式为 full_text， f3是map类型的字段，低下嵌套的 f4 字段指定为 standard。 当指定了部分字段的分词方式后，其余字段的分词方式默认为 `standard`。 具体分词方式以及对搜索的影响可以参考文档[概念&术语](https://developer.qiniu.com/insight/glossary/5101/real-time-warehouse)。仅在新建时生效，更改时不生效，请在日志仓库更改。

  * 云存储仓库名称(`pandora_bucket_name`): 当 `自动导出到七牛云存储(pandora_enable_kodo)` 生效时必填, 默认与实时仓库名称相同，指定云存储的 bucket 名称。
    
  * 添加系统时间(`logkit_send_time`): 默认为 "true"，是否在发送时自动添加发送时间，时间格式为 `RFC3339Nano`。

  * 创建的资源所在区域(`pandora_region`): 必填，Pandora 服务的地域。 

  * 筛选字段(`pandora_schema`): 提供了 schema 的选项和别名功能，如果不填，则认为所有解析出来的字段只要符合实时仓库的字段类型就发送；如果填，可以只选择填了的字段打向实时仓库，根据逗号分隔，如果要以别名的方式打向 实时仓库，加上空格跟上别名即可。若最后以逗号省略号",..."结尾则表示其他字段也以实时仓库的字段类型为准发送。默认程序启动时获取实时仓库的字段类型，若用户缺少一些必填的字段，会帮助填上默认值。
 
  * 压缩发送(`pandora_gzip`): 是否使用 gzip 压缩传输数据，默认开启压缩。注意，压缩会占用 CPU 资源，但是会节省带宽，有利有弊，请根据业务情况选择。

  * 流量限制(`flow_rate_limit`): 每秒的流量限制，单位为 KB,默认不限速，注意填写的为数字字符串，如 "1024"，表示限速每秒 1024 KB，注意，限速并非准确值，会有数值上的偏差，偏差范围在 1KB 以内。若单个 batch 的大小超过了流量限制，logkit-pro 会将 batch 一拆为二。警告：若单个点的大小超过了流量限速的最大限制，logkit Pro 将发送不出该点，请根据单条日志大小谨慎配置。

  * 请求限制(`request_rate_limit`): 每秒请求数限制，默认不限速，注意填写的为数字字符串，如 "500",表示每秒限制最多 500 个请求。注意，限速并发准确值，会有数值上的偏差，偏差范围在每秒 `20` 个请求以内。
  
  * 数据植入UUID(`pandora_uuid`): 是否在数据结果中自动生成 `Pandora_UUID` 字段，默认不开启， `Pandora_UUID` 的生成规则采用 `RFC4122` 中描述的 `V4` 版本 `Random` 规则生成。`padnora_uuid` 功能在数据中自动生成一个 `Pandora_UUID` 字段，该字段保证了发送出去的每一条数据都拥有一个唯一的 `UUID`，可以用于数据去重等需要。
  
  * 自动转换类型(`pandora_force_convert`): 默认不启用。开启后会强制类型转换，如定义的 pandora schema 为 long，而实际的为 string，则会尝试将 string 解析为 long类型（int 64），若无法解析，则忽略该字段内容。使用这个功能可以解决一整条数据中有些字段生成的类型不确定导致写入 Pandora 失败的问题。
  
	* 自动转换时间类型(`pandora_auto_convert_date`) 默认开启。会自动将用户的自动尝试转换为 Pandora 的时间类型(date)，Pandora的时间类型为符合 RFC3339 格式的字符串，若已经符合该类型，则无需开启，关闭可节省 CPU 开销。默认开启，会尝试将进行各种类型的格式转换，包括不同的时间格式字符串的变化，整型作为 unix timestamp 进行转换等等。

  * 数字统一为 float(`number_use_float`): 默认开启，当填为 true 时，会将数据中所有的数字作为 float 类型。该功能适用于数字又有可能是整型又有可能是浮点型的场景，统一作为 float，可避免数据类型冲突。

  * 忽略错误字段(`ignore_invalid_field`): 默认开启，会进行数据格式校验，并忽略不符合格式的字段数据，默认开启，关闭可以节省 CPU 开销。如 Pandora 的类型选择了 jsonstring，若字符串不是合法的 json 字符串，就会忽略改部分字段内容，其他字段正常上报。

  * 服务端反转译换行/制表符(`pandora_unescape`): 默认开启，在 Pandora 服务端反转译`\\n`=>`\n`, `\\t`=>`\t`; 由于 Pandora 数据上传的编码方式会占用`\t`和`\n`这两个符号，所以在sdk中打点时会默认把`\t`转译为`\\t`，把`\n`转译为`\\n`，开启这个选项就是在服务端把这个反转译回来。开启该选项也会转译数据中原有的这些`\\t`和`\\n`符号

  **常用功能**
  
1. 自动创建 Pandora 实时仓库，通过 pandora_auto_create 字段创建。

2. 自动添加 Pandora 数据字段，通过 pandora_schema_free 字段，可以自动更新 Pandora 的实时仓库，添加字段。

3. 流量控制，通过 request_rate_limit 以及 flow_rate_limit 可以控制每秒的请求数以及每秒的请求数据量，若设置的 batchsize 过大导致流量限制，logkit Pro 会自动将 batch 拆分。

4. 压缩传输， 通过 pandora_gzip 配置，可以选择使用 gzip 压缩的方式传输数据，大大节约带宽。

5. 字段选择与别名，通过 pandora_schema 可以选择要发送到 Pandora 的字段，同时可以将 Parser 出的字段名通过别名的方式与 Pandora 的名字进行一一对应。

6. 类型转换，对于解析到的如 string，long 等类型，会根据 Pandora 实际创建的实时仓库字段类型，进行一定的类型转换，可以进行类型转换的 Pandora 字段包括 string(转换为字符串), long(转换为int64整型), float(转换为float64浮点型), date(转换为rfc3339格式的字符串时间表示)，支持的转换为时间类型的数据包括：
  * 精确到微秒的整型（可以从数字、字符串中提取）
  * `2006/01/02 15:04:05`,
  * `2006-01-02 15:04:05 -0700 MST`,
  * `2006-01-02 15:04:05 -0700`,
  * `2006-01-02 15:04:05`,
  * `2006/01/02 15:04:05 -0700 MST`,
  * `2006/01/02 15:04:05 -0700`,
  * `2006-01-02 -0700 MST`,
  * `2006-01-02 -0700`,
  * `2006-01-02`,
  * `2006/01/02 -0700 MST`,
  * `2006/01/02 -0700`,
  * `2006/01/02`,
  * `Mon Jan _2 15:04:05 2006 ANSIC`,
  * `Mon Jan _2 15:04:05 MST 2006 UnixDate`,
  * `Mon Jan 02 15:04:05 -0700 2006 RubyDate`,
  * `02 Jan 06 15:04 MST RFC822`,
  * `02 Jan 06 15:04 -0700 RFC822Z`,
  * `Monday, 02-Jan-06 15:04:05 MST RFC850`,
  * `Mon, 02 Jan 2006 15:04:05 MST RFC1123`,
  * `Mon, 02 Jan 2006 15:04:05 -0700 RFC1123Z`,
  * `2006-01-02T15:04:05Z07:00 RFC3339`,
  * `2006-01-02T15:04:05.999999999Z07:00 RFC3339Nano`,
  * `3:04PM Kitchen`,
  * `Jan _2 15:04:05 Stamp`,
  * `Jan _2 15:04:05.000 StampMilli`,
  * `Jan _2 15:04:05.000000 StampMicro`,
  * `Jan _2 15:04:05.000000000 StampNano`,