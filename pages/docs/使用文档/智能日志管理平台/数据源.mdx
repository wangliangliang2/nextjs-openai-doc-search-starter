数据源是工作流任务的起始节点，它可以接收实时上传的数据（消息队列）或读取离线存储的数据（对象存储或 CDN 日志）。


### **工作流支持以下几种类型的数据源：**

|名称|流式计算|批量计算|备注|
|:--|:--|:--|:--|
|消息队列|yes|no|只能作用于流式计算，实时接收用户上传的数据；每一条进入消息队列的数据，都会被存储 2 天时间，过期自动删除|
|对象存储|no|yes|只能作用于批量计算，可以一次性加载大量数据|
|CDN|no|yes|只能作用于批量计算，数据来源于七牛 CDN 服务|
|HDFS|no|yes|`只能作用于批量计算，仅支持私有云，公有云不提供此服务`|

`注意：`创建好工作流任务之后，消息队列节点会源源不断接收数据。

**消息队列数据源节点相关参数说明**

|参数|必填|说明|
|:---|:---|:---|
| 名称 |是|消息队列名称|
| 字段信息 |是|字段名称和字段类型|
| IP 来源 |否|数据来源的 IP 信息|
| 时间字段|否|数据接收的时间|
| 服务器内部反转译 |否|针对为了写入而被序列化产生的\\t和\\n进行反转译，恢复为\t和\n|


`注意:`通过 logkit-pro 发送数据到智能日志平台，会自动创建一个工作流，工作流中包含数据源节点以及日志导出节点。

**操作演示：**

![](https://pandora-kibana.qiniu.com/workflow/datasource_flow.gif)

**对象存储数据源节点相关参数填写**

|参数|必填|说明|
|:---|:---|:---|
| 名称 |是|对象存储数据源节点名称|
| 空间名称 |是|您要读取的文件所在的 bucket 名称|
| 文件类型 |是|您要读取文件的格式|
| 文件前缀|是|您要读取的文件名称的前缀|

**操作演示**

![](https://pandora-kibana.qiniu.com/workflow/kodo_datasource.gif)

**CDN 日志数据源节点相关参数填写**

|参数|必填|说明|
|:---|:---|:---|
| 名称 |是|CDN 日志数据源节点名称|
| 域名 |是|您的 CDN 服务的域名|
| 文件过滤条件类型 |是|日志产生的时间范围的选择方式（固定时间/相对时间），与文件过滤条件结合起来使用|
| 文件过滤条件 |是|具体的文件过滤时间|

`注意：`CDN 日志数据源的字段类型不可更改，与七牛 CDN 服务产生的日志格式一致。

**操作演示**

![](https://pandora-kibana.qiniu.com/workflow/cdn_datasource.gif)

当文件过滤条件类型选择“相对时间”时，过滤条件里可以引入`魔法变量`。

提前创建一个魔法变量：

![](https://pandora-kibana.qiniu.com/workflow/magic_variable.png)

创建 CDN 日志数据源节点时，选择文件过滤条件类型为“相对时间”，过滤条件里引入魔法变量即可。

![](https://pandora-kibana.qiniu.com/relative-time.png)

关于魔法变量详情请阅读[魔法变量](/insight/manual/4690/data-calculation#5)。
