file reader是logkit从文件读取日志的配置方式，共包含 `dir`、`file`、`tailx`、`fileauto` 和 `dirx` 五种模式。

# **dir 模式，从文件夹中读取**

填写日志所在文件夹路径(log_path)，如 `/Users/loris/logdir/`，logkit-pro 在启动时根据文件夹下文件更新时间顺序依次读取文件，读取到时间最新的文件时会不断读取追加的数据，直到该文件夹下出现新的文件。
特点：一个时间点只会追踪一个文件。文件夹中已经读取完毕的文件不会再次读取，全部读完时，会追踪文件夹中最新的文件，因此如果最新的文件中有追加数据，可以继续读取，一旦再次出现新的文件，则追踪最新的文件。

## **收集场景**

使用 `dir` 模式的经典日志存储方式为整个文件夹下存储单个服务的业务日志，文件夹下的日志通常有统一前缀，后缀为时间戳，根据日志的大小 rotate 到新的文件。如配置的文件夹为 `logdir`，下面的文件为 `logdir/a.log.20170621` , `logdir/a.log.20170622`, `logdir/a.log.20170623` 这种模式的日志。即某个服务日志按文件大小分隔日志，每次分割后新命名文件并以时间戳为后缀，并且该文件夹下只有这一个服务。`dir 模式`首先会对文件夹下文件整体排序，依次读取各个文件，读完最后有个文件后会查找时间(文件 ctime)更新文件并重新排序，依次循环。logkit-pro 会负责将多个文件串联起来。即数据读取过程中 `a.log.20170621` 中最后一行的下一行就是 `a.log.20170622` 的第一行。

# **file 模式，从文件中读取**

填写精确的日志文件路径(log_path)，如 `/Users/loris/logdir/my.log`，logkit-pro 不断读取该文件追加的数据。 

## **收集场景**

使用 `file` 模式的经典日志存储方式类似于 `nginx` 的日志 `rotate 方式`，日志名称为固定的名称，如 `access.log` , `rotate` 时直接 `move` 成新的文件如 `access.log.1`，新的数据仍然写入到 `access.log`。此时  配置 logkit-pro 收集永远只针对 `access.log` 这一个固定名称的文件进行收集。对于 logkit-pro 来说, Runner 也只会不断收集 `access.log` 这一个文件。检测文件是否 rotate 成功的标志是文件的 `inode` 号，在 windows 下则是 `fd` 的属性编号。对于使用 `nfs` 系统的用户来说，由于 `inode` 号不稳定，请谨慎使用这个模式。

# **tailx模式，按通配符匹配多个文件读取**

填写匹配路径的模式串(log_path)，例如 `/Users/*/path/*/logdir/*.log*`。

支持读取以 `.gz` 为后缀的压缩文件，路径填写如 `/Users/*/path/*/logdir/*.gz`

## **收集场景**

使用 `tailx` 模式的场景可以比较灵活，几乎可以读取所有被通配符匹配上的日志文件，对于单个日志文件使用 file 模式不断追踪日志更新，`logpath` 是一个匹配路径的模式串，例如 `/home/*/path/*/logdir/*.log*`, 此时会展开并匹配所有符合该表达式的文件，并持续读取所有有数据追加的文件。每隔 `stat_interval` 的时间，重新刷新一遍 `logpath` 模式串，添加新增的文件。需要注意的是，使用 `tailx 模式`容易导致文件句柄打开过多。`tailx 模式`的文件重复判断标准为文件名称，若使用 `rename`, `copy` 等方式改变日志名称，并且新的名字在 `logpath` 模式串的包含范围内，在 `read_from` 为 `oldest` 的情况下则会导致重复写入数据，设置为 `newest` 则有可能在感知的时间周期内丢失一部分数据。选择 `tailx 模式`请谨慎配置文件名称，防止日志 rotate 时老数据的命名进入 tailx 的模式串范围内，导致不断重复读取数据。
特点：一个时间点会追踪多个文件。追踪所有匹配的文件，一如果设置了句柄数限制，匹配的文件数大于句柄数，则可能会有一批文件无法追踪，此时建议设置过期时间，过期时间表示多长时间没有修改之后就不再追踪该文件，例如追踪时间为1h，如果文件修改时间为1小时之前，则不会追踪该文件，当该文件中有数据写入时，文件修改时间发生了变化，小雨1小时则下次会继续追踪。

## **风险点**
由于用户对日志文件的归档行为存在以下情况：inode不变，直接覆盖文件内容。原始日志文件已读取到的 offset 和覆盖后的日志文件大小存在不可预知的相对大小关系。于是会引起以下两种情况的数据丢失。
1）原始日志文件已读取的 offset 大于覆盖后的日志文件，`tailx` 模式能感知到文件被覆盖了，会立即从头开始读覆盖后的文件，导致原始日志文件里 offset 到 原始日志文件末尾的内容未被读取，这部分日志数据丢失；
2）原始日志文件已读取的 offset 小于等于覆盖后的日志文件，`tailx` 模式感知不到文件被覆盖，会继续用 offset 读覆盖后的文件，导致覆盖后的日志文件从开头到 offset 处的日志被忽略。

# **fileauto模式，根据路径自动选择模式从文件中读取**

自动根据用户上传的路径匹配上述三种文件读取模式中的一种。

选择的策略如下：

1. 判断路径中是否带有 `*` ， 若包含，则选择 tailx 模式。
2. 判断路径是否为文件夹，若是文件夹，则选择 `dir` 模式。注意：`dir` 模式下，不同文件不断追加，会导致数据重复收集，请手动选择 `tailx` 模式。
3. 若以 `.tar.gz`，`.tar`，`.zip` 结尾，选择`dirx` 模式，若以 `.gz`结尾则选择 `tailx` 模式
4. 最后选择 `file` 模式。

# **dirx模式，按通配符匹配多个目录读取其中的文件**

填写匹配路径的模式串(log_path)，例如 `/Users/*/path/*/logdir/`。

支持读取以 `.tar.gz`，`.tar`，`.zip` 为后缀的压缩文件，路径填写如 `/Users/*/path/*/logdir/*.tar`

## **收集场景**

使用`dirx` 模式的场景主要解决有通配符需求，但是通配到的是文件夹，文件夹按照dir模式产生日志。`dirx` 可以读取所有被通配符匹配上的日志目录，对于单个日志目录使用 `dir` 模式不断追踪日志更新，`logpath` 是一个匹配路径的模式串，例如 `/home/*/path/*/logdir/`, 此时会展开并匹配所有符合该表达式的目录，并持续读取这些目录下所有有数据追加的文件。每隔 `stat_interval` 的时间，重新刷新一遍 `logpath` 模式串，添加新增的目录。需要注意的是，使用 `dirx 模式`容易导致文件句柄打开过多。`dirx 模式`的目录和文件重复判断标准为文件名称，若使用 `rename`, `copy` 等方式改变日志名称，并且新的名字在 `logpath` 模式串的包含范围内，在 `read_from` 为 `oldest` 的情况下则会导致重复写入数据，设置为 `newest` 则有可能在感知的时间周期内丢失一部分数据。选择 `dirx 模式`请谨慎配置文件名称，防止日志 rotate 时老数据的命名进入 dirx 的模式串范围内，导致不断重复读取数据。`dirx 模式` 下对目录过期的判断是当目录下所有的文件全部过期才将该目录标记为过期。
特点：一个时间点会追踪多个目录下的最新文件。


# **读取完成后自动删除原始日志**

在文件读取的几个模式中，都可以看到如下图所示的选项： `是否自动删除日志文件`， 该功能是为方便用户节省磁盘空间，在读取后进行自动删除。

![](https://dn-odum9helk.qbox.me/FikmqWKUrx2JzLWFD_jn98n8udWw)

* 删除执行周期(`delete_interval`) cleaner执行周期，会在每个周期检查是否符合删除的条件，单位为秒(s)，到了删除周期，且检测发现符合删除条件的数据会被删除，reader读取完毕后会生成file.done文件，当整个file.done文件里的日志都被发送至mgr删除时，文件名会变为file.deleted。
* 最大保留已读文件数(`reserve_file_number`) 最大保留的已读取文件数，当超过这个数量时就会把多出的文件删除，默认为保留 10 个.
* 最大保留已读文件总大小(`reserve_file_size`) 最大保留已读文件总大小，当已读文件的总大小超过这个值时，会把最老的那部分删掉，默认保留 2GB，单位为 `MB`.

> `reserve_file_number` 和 `reserve_file_size` 这两个条件只要满足其一，且文件在`file.done`（表示文件已经读取完毕），就会触发删除。
> 注意 `tailx` 和 `dirx` 模式请使用 自动删除读取完毕的文件(`expire_delete`) 功能。


## **多个收集器读取同一份日志时删除如何运行？**

配置了随日志删除以后，就代表声明了要对删除文件进行控制，当同一个日志目录有多个收集任务在读取时，不配置自动删除的收集器，就表示放弃控制日志的删除。
一份日志目录被多个配置删除的收集器控制时，只有当所有的收集器都读完，才执行删除日志。

> 补充说明： 收集器的删除，仅删除已经读取过的日志，不经过 logkit-pro 读取的日志无法删除。
> 若仅想通过 logkit-pro 删除日志，可以配置 `raw` parser 和`discard` sender，前者不进行任何解析，后者不发送到任何目的地址，同时日志也能删除。

# **基础配置信息**

  * 读取起始位置(`read_from`)：在创建新文件或 meta 信息损坏的时候(即历史读取记录不存在)，将从文件的哪个位置开始读取。可以设置为 oldest，从`文件开始的位置全量`读取，也可以设置为 newest 从logkit`开始运行后文件新追加的部分`开始读取。如果字段不填，默认从`最老`的开始消费。tailx 读取模式下，设置为 oldest 模式可能会导致数据重复读取(在 rotate 的方式是 copy 一份数据时会出现)，设置为 newest 则有可能在`感知到新文件出现的时间周期内丢失一部分在这个时间周期内产生的数据`。
  
  * 忽略文件的最大过期时间(`expire`)：针对 tailx 和 dirx 读取模式读取的日志, 写法为数字加单位符号组成的字符串 `duration` 写法，支持`时 h、分 m、秒 s` 为单位,类似 `3h(3小时),10m(10分钟),5s(5秒)`, tailx 默认的 expire 时间是 `24h`，dirx 默认的 expire 时间是 `0s`（即永不过期）, 当达到 expire 时间的日志，就放弃追踪。在过期时间为 0s 时如果 dirx 追踪的目录较多，建议调大最大打开文件数(`max_open_files`)。
  
  * 清理元数据的过期时间(`submeta_expire`)：针对 tailx 和 dirx 读取模式读取的日志，当元数据的文件达到expire时间，则对其进行清理操作。写法为数字加单位符号组成的字符串 `duration` 写法，支持`时 h、分 m、秒 s` 为单位,类似 `3h(3小时),10m(10分钟),5s(5秒)`, tailx 和 dirx 默认的 submeta_expire 时间是 `720h`，即 30 天。

  * 自动删除读取完毕的文件(`expire_delete`)： 自动删除已经读取完毕并且已经达到过期时间的文件/文件夹，压缩文件读完就认为已经过期。

# **高级选项**

   * 数据保存路径(`meta_path`)：reader 读取 `offset` 的记录路径，必须是一个文件夹，在这个文件夹下，会记录本次 reader 的读取位置。默认会根收集器名称结合上传路径的 `hash 值`自动生成。`注意，如果指定该选项，请确保每个配置的保存路径各不相同`.
   
   * 忽略文件/文件夹路径(`ignore_log_path`): 默认不填，tailx/dirx时生效，忽略符合该路径的文件。
   
   * 编码方式(`encoding`)：读取日志文件的编码方式，默认为 `utf-8`，即按照 `utf-8` 的编码方式读取文件。支持读取文件的编码格式包括：`UTF-16`，`GB18030`，`GBK(GB2312可使用GBK编码)`，`cp51932`，`windows-51932`，`EUC-JP`，`EUC-KR`，`ISO-2022-JP`，`Shift_JIS`，`TCVN3` 及其相关国际化通用别名。

   * 读取速度限制(`readio_limit`)：读取文件的磁盘限速，填写正整数，单位为 `MB/s`, v1.2.3之前的版本默认限速 `20 MB/s`，在v1.2.3之后默认不开启。
   
   * 来源标签(`datasource_tag`)：表示把读取日志的路径名称也作为标签，记录到解析出来的数据结果中，默认不添加，若 `datasource_tag` 不为空，则以该字段名称作为标签名称。例如 `"datasource_tag":"mydatasource"`; 则最终解析的日志中会增加一个字段 `mydatasource` 记录读取到日志的路径。可用于区分 `tailx 模式`下的日志数据是从哪个日志路径下读取的问题。`dir 模式`下，可能存在部分数据标记的不准确，偏差到下一个文件。（因为读取的时候是读到 `bufferreader` 的缓冲区，所以当`buffer reader`还在读前一部分数据的时候，可能底层的多文件拼接的`seq reader`已经读取到下一个文件，而此时调用的结果会是下一个文件的结果，所以出现异常。这种情况只有在数据出现在文件末尾且缓冲区已经读到下一个文件的情况。）
   
   * 编码方式标签(`encode_tag`)：表示把读取日志的编码方式记录在该标签名称中，默认为空，表示不添加，若 `encode_tag` 不为空，则以该字段名称作为标签名称。例如 `"encode_tag":"encode"`; 则最终解析的日志中会增加一个字段 `encode` 记录读取日志的编码方式。
   
   * 按正则表达式规则换行(`head_pattern`)：默认不填，reader 每次读取一行，若要读取多行，则填写。`head_pattern`表示匹配多行的第一行使用的正则表达式。`tailx 模式`在多行匹配时，若一条日志的多行被截断到多个文件，那么此时无法匹配多行。`dir、file 模式`下会自动处理文件截断的拼接。`head_pattern`最多缓存 `20MB`的日志文件进行匹配。使用多行匹配情况的一个经典场景就是使用`grok parser`解析应用日志，此时需要在`head_pattern`中指定行首的正则表达式，每当匹配到符合行首正则表达式的时候，就将之前的多行一起返回，交由后面的`parser`解析。
   
   * 运行时间(`run_time`)：默认不填，表示运行，仅 `file` 和 `tailx` 模式生效。写法为 `hh:mm-hh:mm` ，24小时制，仅支持到分钟级别，若超过24小时，进行取余，若超过60分钟，也取余。例如 `12:10-13:10` 表示每天的 12:10 到 13:10 之间运行。若开始时间结束时间相同则默认运行。
   
   * 文件末尾加上换行符(`newfile_newline`)：默认为`false`，只针对`dir模式`，开启后，不同文件结尾自动添加换行符。
   
   * 是否忽略隐藏文件(`ignore_hidden`)：读取的过程中是否忽略隐藏文件，默认忽略。
   
   * 忽略此类后缀文件(`ignore_file_suffix`)：针对 dir 读取模式需要解析的日志文件，可以设置读取的过程中忽略哪些文件后缀名，默认忽略的后缀包括`".pid"`, `".swap"`, `".go"`, `".conf"`, `".tar.gz"`, `".tar"`, `".zip"`,`".a"`, `".o"`, `".so"`。
   
   * 以 linux 通配符匹配文件(`valid_file_pattern`)：针对 `dir 读取模式`需要解析的日志文件，可以设置匹配文件名的模式串，匹配方式为 linux 通配符展开方式，默认为 `*`，即匹配文件夹下全部文件。
      * 通配符语法说明：
      * 匹配任意非文件路径分隔符的零或多个字符
      * ? 匹配任意非文件路径分隔符的单个字符
      * [符号集] 匹配符号集中的所有字符
      
	 * 是否读取已经读完的文件(`read_same_inode`): 已经读完的文件（这个定义在程序中是用inode号相同来判断的）是否继续读取，在`dir`模式下，可以通过开启这个选项来达到循环读取目录中文件（生成10个文件，文件名循环利用的模式）的效果。
	 
   * 最大打开文件数(`max_open_files`)：针对 `tailx 和 dirx 读取模式`读取的日志，最大能追踪的文件数，默认为 `256`。同时追踪的文件过多会导致打开的文件句柄超过系统限制，请谨慎配置该项。超过限制后，不再追踪新添加的日志文件，直到部分追踪文件或目录达到 `expire 时间`。
   
   * 扫描间隔(`stat_interval`)：针对 `tailx 和 dirx 读取模式`读取的日志，刷新过期的跟踪日志文件, 刷新 `logpath` 模式串，感知新增日志的定时检查时间, 写法为数字加单位符号组成的字符串 `duration` 写法，支持`时 h、分m、秒s`为单位,类似`3h(3小时),10m(10分钟),5s(5秒)`,`默认3m(3分钟)`。