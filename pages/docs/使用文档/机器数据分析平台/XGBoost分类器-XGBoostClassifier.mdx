XGBoost分类器是GBDT分类器的一种优化算法，通过添加正则化、并行处理、内置交叉验证等方法加快计算速度，优化模型表现。

**语法：**
```
..| fit XGBClassifier booster=<gbree(default) | gblinear> eta=<float> min_child_weight=<int> max_depth=<int> gamma=<int> subsample=<float> objective=<"binary:logistic" | "binary:logitraw" |  "multi:softmax" | "multi:softprob"> eval_metric=<logloss | error | merror | mlogloss | auc> num_class=<int> lambda=<float> alpha=<float> random_state=<int> <target_field> from <feature_field_1> <feature_field_2>... 
```

**参数说明：**

- booster用来选择迭代计算的模型。
	+ booster=gbtree（默认值），使用基于树的模型进行提升计算
	+ booster=gblinear，使用线性模型进行提升计算
- eta用来指定收缩步长，即每个弱学习器的权重缩减系数，用于防止对负梯度方向的过拟合，提高模型的泛化能力，必须为(0,1]之间的float。eta通过缩减特征的权重使提升计算过程更加保守。默认为0.3。
- min_child_weight
	+ 在booster=gbtree的情况下，用来指定子节点中最小的样本权重和，用于避免过拟合。如果一个叶子节点的样本权重和小于min_child_weight则拆分过程结束。
	+ 在booster=gblinear的情况下，这个参数是指建立每个模型所需要的最小样本数。
	+ 默认值为1。
- max_depth用来指定数的最大深度，若不提供，则默认值为6。
- gamma用来指定节点分裂所需的最小损失函数下降值。在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。这个参数的值越大，算法越保守。默认为0。
- subsample用来决定样本采样比例，必须为(0,1]之间的float。算法采用无放回的采样方式，如果subsample=1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做决策树拟合。默认为1。
- objective用来指定学习任务及相应的学习目标。
	+ objective=binary:logistic，二分类的逻辑回归问题，输出为概率。
	+ objective=binary:logitraw，二分类的逻辑回归问题，输出的结果为wTx。
	+ objective=multi:softmax，采用softmax目标函数处理多分类问题，同时需要设置参数num_class（类别个数）
	+ objective=multi:softprob，和softmax一样，但是输出的是ndata * nclass的向量。
	+ 在二分类的场景下，objective默认为“binary:logistic"，在多分类的场景下，objective默认为“multi:softprob"。如果设置的学习任务和实际数据有矛盾（例如在多分类问题的情况下，设置objective="binary:logistic"），XGBClassifier会自动将objective调整为符合数据情况的默认值（在之前的例子中，会把object自动更改为“multi:softprob”）。
- eval_metric用来指定校验数据所需要的评价指标，不同的目标函数会支持不同的评价指标。
	+ eval_metric=logloss, 负对数似然函数值
	+ eval_metric=error, 二分类错误率(阈值为0.5)
	+ eval_metric=merror, 多分类错误率
	+ eval_metric=mlogloss, 多分类logloss损失函数
	+ eval_metric=auc，曲线下面积
	+ 在二分类的场景下，eval_metric默认为error，在多分类的场景下，eval_metric默认为merror
- num_class用来指定类别个数。当objective选择multi的时候需要设置该参数
- lambda用来指定L2正则化的惩罚系数，可以用来降低过拟合。
- alpha用来指定L1正则化的惩罚系数，这样有助于提升计算的速度。
- random_state为随机数种子，用来控制样本自助抽样的随机性和特征抽样的随机性。如果给定特定值，重新跑模型的时候，可以得出同样的结果。



<h2 id="1.6"><strong>伯努利朴素贝叶斯分类器 - BernoulliNB</strong></h2>
朴素贝叶斯模型在伯努利分布假设下的实现。适用于二分类场景。

```
..| fit BernoulliNB alpha=<float> binarize=<float> fit_prior=<True(default) | False> <target_field> from <feature_field_1> <feature_field_2>... 
```

**参数说明：**

- alpha用来指定拉普拉斯平滑的系数，默认值为1.0。

- binarize用来指定特征映射到二分变量的阈值，默认值为0.0。

- fit_prior用来指定是否要学习一个先验分布，如果设为False，采用均匀分布作为先验分布。默认值为True。

  

<h2 id="1.7"><strong>高斯朴素贝叶斯分类器 - GaussianNB</strong></h2>
朴素贝叶斯模型在高斯分布假设下的实现。适用于二分类场景。

这个算子没有可调节参数。

```
..| fit GaussianNB <target_field> from <feature_field_1> <feature_field_2>... 
```
