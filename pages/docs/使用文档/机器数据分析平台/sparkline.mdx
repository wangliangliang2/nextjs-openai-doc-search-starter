sparkline 会将时间范围内的事件按照literal进行分组，通过与聚合算子stats、chart结合起来一起使用绘制事件内联图表。


**语法**

```
aggregation_command sparkline(<StatsFunc(field)>, literal) [as field]……[by filed][, fieldn] [, sparkline(<StatsFunc(field)>, literal) [as field]……[by filed][, fieldn]]...
```

**参数说明**

必填参数：

* `aggregation_command`: 支持的聚合算子包括stats、chart，其中chart只支持一个分组

* `StatsFunc(field)`: 指定函数名称、统计字段。

可选参数：

* `as field`: 将统计结果放入指定的新字段中。

* `by filed`: 指定分组字段名称。如果未指定分组字段，stats 命令只返回一行所有日志的聚合结果。

* `literal`: 可以为数字，或者数字+时间单位，比如 1， 1s， 1d等等，如果不填写literal，默认是10s。

> 以stats sparkline(count(),literal)为例
> - 如果literal是整数N，则sparkline会将时间范围分为N组，每组的count就是该组时间范围内的事件个数，如果N大于总事件数则把N置为事件总数量。
> - 如果literal是整数N+时间单位T，当T为s、m、h时literal会对齐到0，当T为y时对齐到本年第一天，q对齐到本季度第一天，当T为M时对齐到本月第一天，当T为W时对齐到本周第一天。
>   - 目前存在以下几种时间分组大小：1s、5s、10s、15s、30s、1m、5m、10m、15m、30m、1h、6h、12h、1d、7d、30d，分组大小是上述分组取值中>=literal的最小值，如literal是35min，则按1h进行分组。
  


  
**使用示例**

与stats一起使用

1. search repo="sparkline" | stats sparkline(count()) by host
2. search repo="sparkline" | stats sparkline(count(), 10) by host
3. search repo="sparkline" | stats sparkline(count(), 1d) by host

与chart一起使用

1. search repo="sparkline" | chart sparkline(count(), 1d) by number bins = 100