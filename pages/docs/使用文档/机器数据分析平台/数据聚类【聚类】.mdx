**使用场景**

当我们需要将连续数据或离散数据通过其特征相似性合并成几个大类的时候，我们通常使用聚类算法（Clustering）来解决问题。

分类和聚类算法的目的都是将数据判断成某一类，但他们训练所需的数据不同。分类算法是一种监督性学习方法，意味着在训练模型的时候，样本数据中必须包含每一行数据的属性特征及其所属的类别，目的是将每一条记录分别属于哪一类标记出来。而聚类算法为非监督性学习，意味着在训练模型的时候，样本数据中只包含每一行数据的属性特征，但是并不知道他们所属的类别。目的只是根据提供的属性特征，把相似的东西聚到一起。


**通用语法：**

```
...|fit <algo_name> [options] <feature_field_1> <feature_field_2> [into model_name]... 
```

**通用参数说明：**

- <algo_name> 必填，用来指定训练模型采用的算法名称。
- [options]可选，为算法的内置参数，根据提供的算法变化。
- <feature_field> 必填，可以是一个或者多个字段，用来指定建模使用的特征字段，给定的feature_field值必须存在于数据集中。
- [into model_name]可选，用来将fit训练出来的模型保存成model_name以便下次调用。需要注意的是，只有K均值算法支持保存模型，层次聚类法不支持模型的保存和重新应用。如果需要用层级聚类法做新数据集的聚类分析，则需要直接在新数据上用层次聚类法训练产生模型。
- 数据集必须不为空。


以下算法可以用来预测未来某个时间的连续指标：

- [K均值 - KMeans](/express/manual/11059/k-means-kmeans)
- [层次聚类法 -  Hierarchical Clustering](/express/manual/11060/hierarchical-clustering-method-hierarchical-clustering)
- [谱聚类 - Spectral Clustering](/express/manual/11061/spectral-clustering-spectral-clustering)
- [密度聚类算法 - DBSCAN](/express/manual/11062/density-dbscan-clustering-algorithm)
- [Birch聚类 - Birch](/express/manual/11063/birch-clustering-birch)


